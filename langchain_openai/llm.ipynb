{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "16236e40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package                 Version\n",
      "----------------------- -----------\n",
      "asttokens               3.0.0\n",
      "colorama                0.4.6\n",
      "comm                    0.2.2\n",
      "debugpy                 1.8.14\n",
      "decorator               5.2.1\n",
      "executing               2.2.0\n",
      "ipykernel               6.29.5\n",
      "ipython                 9.2.0\n",
      "ipython_pygments_lexers 1.1.1\n",
      "jedi                    0.19.2\n",
      "jupyter_client          8.6.3\n",
      "jupyter_core            5.7.2\n",
      "matplotlib-inline       0.1.7\n",
      "nest-asyncio            1.6.0\n",
      "packaging               25.0\n",
      "parso                   0.8.4\n",
      "pip                     25.1.1\n",
      "platformdirs            4.3.8\n",
      "prompt_toolkit          3.0.51\n",
      "psutil                  7.0.0\n",
      "pure_eval               0.2.3\n",
      "Pygments                2.19.1\n",
      "python-dateutil         2.9.0.post0\n",
      "pywin32                 310\n",
      "pyzmq                   26.4.0\n",
      "six                     1.17.0\n",
      "stack-data              0.6.3\n",
      "tornado                 6.5.1\n",
      "traitlets               5.14.3\n",
      "wcwidth                 0.2.13\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d4cfbc91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openai\n",
      "  Downloading openai-1.82.0-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting langchain-openai\n",
      "  Downloading langchain_openai-0.3.18-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting anyio<5,>=3.5.0 (from openai)\n",
      "  Using cached anyio-4.9.0-py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting distro<2,>=1.7.0 (from openai)\n",
      "  Using cached distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting httpx<1,>=0.23.0 (from openai)\n",
      "  Using cached httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting jiter<1,>=0.4.0 (from openai)\n",
      "  Using cached jiter-0.10.0-cp313-cp313-win_amd64.whl.metadata (5.3 kB)\n",
      "Collecting pydantic<3,>=1.9.0 (from openai)\n",
      "  Downloading pydantic-2.11.5-py3-none-any.whl.metadata (67 kB)\n",
      "Collecting sniffio (from openai)\n",
      "  Using cached sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting tqdm>4 (from openai)\n",
      "  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting typing-extensions<5,>=4.11 (from openai)\n",
      "  Using cached typing_extensions-4.13.2-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting idna>=2.8 (from anyio<5,>=3.5.0->openai)\n",
      "  Using cached idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting certifi (from httpx<1,>=0.23.0->openai)\n",
      "  Using cached certifi-2025.4.26-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
      "  Using cached httpcore-1.0.9-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting h11>=0.16 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
      "  Using cached h11-0.16.0-py3-none-any.whl.metadata (8.3 kB)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic<3,>=1.9.0->openai)\n",
      "  Using cached annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.33.2 (from pydantic<3,>=1.9.0->openai)\n",
      "  Using cached pydantic_core-2.33.2-cp313-cp313-win_amd64.whl.metadata (6.9 kB)\n",
      "Collecting typing-inspection>=0.4.0 (from pydantic<3,>=1.9.0->openai)\n",
      "  Downloading typing_inspection-0.4.1-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting langchain-core<1.0.0,>=0.3.61 (from langchain-openai)\n",
      "  Downloading langchain_core-0.3.61-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting tiktoken<1,>=0.7 (from langchain-openai)\n",
      "  Using cached tiktoken-0.9.0-cp313-cp313-win_amd64.whl.metadata (6.8 kB)\n",
      "Collecting langsmith<0.4,>=0.1.126 (from langchain-core<1.0.0,>=0.3.61->langchain-openai)\n",
      "  Using cached langsmith-0.3.42-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting tenacity!=8.4.0,<10.0.0,>=8.1.0 (from langchain-core<1.0.0,>=0.3.61->langchain-openai)\n",
      "  Using cached tenacity-9.1.2-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting jsonpatch<2.0,>=1.33 (from langchain-core<1.0.0,>=0.3.61->langchain-openai)\n",
      "  Using cached jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting PyYAML>=5.3 (from langchain-core<1.0.0,>=0.3.61->langchain-openai)\n",
      "  Using cached PyYAML-6.0.2-cp313-cp313-win_amd64.whl.metadata (2.1 kB)\n",
      "Collecting packaging<25,>=23.2 (from langchain-core<1.0.0,>=0.3.61->langchain-openai)\n",
      "  Using cached packaging-24.2-py3-none-any.whl.metadata (3.2 kB)\n",
      "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.61->langchain-openai)\n",
      "  Using cached jsonpointer-3.0.0-py2.py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting orjson<4.0.0,>=3.9.14 (from langsmith<0.4,>=0.1.126->langchain-core<1.0.0,>=0.3.61->langchain-openai)\n",
      "  Using cached orjson-3.10.18-cp313-cp313-win_amd64.whl.metadata (43 kB)\n",
      "Collecting requests<3,>=2 (from langsmith<0.4,>=0.1.126->langchain-core<1.0.0,>=0.3.61->langchain-openai)\n",
      "  Using cached requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting requests-toolbelt<2.0.0,>=1.0.0 (from langsmith<0.4,>=0.1.126->langchain-core<1.0.0,>=0.3.61->langchain-openai)\n",
      "  Using cached requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\n",
      "Collecting zstandard<0.24.0,>=0.23.0 (from langsmith<0.4,>=0.1.126->langchain-core<1.0.0,>=0.3.61->langchain-openai)\n",
      "  Using cached zstandard-0.23.0-cp313-cp313-win_amd64.whl.metadata (3.0 kB)\n",
      "Collecting charset-normalizer<4,>=2 (from requests<3,>=2->langsmith<0.4,>=0.1.126->langchain-core<1.0.0,>=0.3.61->langchain-openai)\n",
      "  Using cached charset_normalizer-3.4.2-cp313-cp313-win_amd64.whl.metadata (36 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests<3,>=2->langsmith<0.4,>=0.1.126->langchain-core<1.0.0,>=0.3.61->langchain-openai)\n",
      "  Using cached urllib3-2.4.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting regex>=2022.1.18 (from tiktoken<1,>=0.7->langchain-openai)\n",
      "  Using cached regex-2024.11.6-cp313-cp313-win_amd64.whl.metadata (41 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\wellington\\documents\\projetos\\github\\asimov\\langchain\\.venv\\lib\\site-packages (from tqdm>4->openai) (0.4.6)\n",
      "Downloading openai-1.82.0-py3-none-any.whl (720 kB)\n",
      "   ---------------------------------------- 0.0/720.4 kB ? eta -:--:--\n",
      "   --------------------------------------- 720.4/720.4 kB 21.4 MB/s eta 0:00:00\n",
      "Using cached anyio-4.9.0-py3-none-any.whl (100 kB)\n",
      "Using cached distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Using cached httpx-0.28.1-py3-none-any.whl (73 kB)\n",
      "Using cached httpcore-1.0.9-py3-none-any.whl (78 kB)\n",
      "Using cached jiter-0.10.0-cp313-cp313-win_amd64.whl (205 kB)\n",
      "Downloading pydantic-2.11.5-py3-none-any.whl (444 kB)\n",
      "Using cached pydantic_core-2.33.2-cp313-cp313-win_amd64.whl (2.0 MB)\n",
      "Using cached typing_extensions-4.13.2-py3-none-any.whl (45 kB)\n",
      "Downloading langchain_openai-0.3.18-py3-none-any.whl (63 kB)\n",
      "Downloading langchain_core-0.3.61-py3-none-any.whl (438 kB)\n",
      "Using cached jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Using cached langsmith-0.3.42-py3-none-any.whl (360 kB)\n",
      "Using cached orjson-3.10.18-cp313-cp313-win_amd64.whl (134 kB)\n",
      "Using cached packaging-24.2-py3-none-any.whl (65 kB)\n",
      "Using cached requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "Using cached charset_normalizer-3.4.2-cp313-cp313-win_amd64.whl (105 kB)\n",
      "Using cached idna-3.10-py3-none-any.whl (70 kB)\n",
      "Using cached requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
      "Using cached tenacity-9.1.2-py3-none-any.whl (28 kB)\n",
      "Using cached tiktoken-0.9.0-cp313-cp313-win_amd64.whl (894 kB)\n",
      "Using cached urllib3-2.4.0-py3-none-any.whl (128 kB)\n",
      "Using cached zstandard-0.23.0-cp313-cp313-win_amd64.whl (495 kB)\n",
      "Using cached annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Using cached certifi-2025.4.26-py3-none-any.whl (159 kB)\n",
      "Using cached h11-0.16.0-py3-none-any.whl (37 kB)\n",
      "Using cached jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n",
      "Using cached PyYAML-6.0.2-cp313-cp313-win_amd64.whl (156 kB)\n",
      "Using cached regex-2024.11.6-cp313-cp313-win_amd64.whl (273 kB)\n",
      "Using cached sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Downloading typing_inspection-0.4.1-py3-none-any.whl (14 kB)\n",
      "Installing collected packages: zstandard, urllib3, typing-extensions, tqdm, tenacity, sniffio, regex, PyYAML, packaging, orjson, jsonpointer, jiter, idna, h11, distro, charset-normalizer, certifi, annotated-types, typing-inspection, requests, pydantic-core, jsonpatch, httpcore, anyio, tiktoken, requests-toolbelt, pydantic, httpx, openai, langsmith, langchain-core, langchain-openai\n",
      "\n",
      "   - --------------------------------------  1/32 [urllib3]\n",
      "   -- -------------------------------------  2/32 [typing-extensions]\n",
      "   --- ------------------------------------  3/32 [tqdm]\n",
      "   ------- --------------------------------  6/32 [regex]\n",
      "   -------- -------------------------------  7/32 [PyYAML]\n",
      "  Attempting uninstall: packaging\n",
      "   -------- -------------------------------  7/32 [PyYAML]\n",
      "    Found existing installation: packaging 25.0\n",
      "   -------- -------------------------------  7/32 [PyYAML]\n",
      "    Uninstalling packaging-25.0:\n",
      "   -------- -------------------------------  7/32 [PyYAML]\n",
      "      Successfully uninstalled packaging-25.0\n",
      "   -------- -------------------------------  7/32 [PyYAML]\n",
      "   ---------- -----------------------------  8/32 [packaging]\n",
      "   --------------- ------------------------ 12/32 [idna]\n",
      "   ---------------- ----------------------- 13/32 [h11]\n",
      "   ------------------ --------------------- 15/32 [charset-normalizer]\n",
      "   ----------------------- ---------------- 19/32 [requests]\n",
      "   -------------------------- ------------- 21/32 [jsonpatch]\n",
      "   --------------------------- ------------ 22/32 [httpcore]\n",
      "   ---------------------------- ----------- 23/32 [anyio]\n",
      "   ---------------------------- ----------- 23/32 [anyio]\n",
      "   ------------------------------- -------- 25/32 [requests-toolbelt]\n",
      "   -------------------------------- ------- 26/32 [pydantic]\n",
      "   -------------------------------- ------- 26/32 [pydantic]\n",
      "   -------------------------------- ------- 26/32 [pydantic]\n",
      "   -------------------------------- ------- 26/32 [pydantic]\n",
      "   -------------------------------- ------- 26/32 [pydantic]\n",
      "   -------------------------------- ------- 26/32 [pydantic]\n",
      "   --------------------------------- ------ 27/32 [httpx]\n",
      "   ----------------------------------- ---- 28/32 [openai]\n",
      "   ----------------------------------- ---- 28/32 [openai]\n",
      "   ----------------------------------- ---- 28/32 [openai]\n",
      "   ----------------------------------- ---- 28/32 [openai]\n",
      "   ----------------------------------- ---- 28/32 [openai]\n",
      "   ----------------------------------- ---- 28/32 [openai]\n",
      "   ----------------------------------- ---- 28/32 [openai]\n",
      "   ----------------------------------- ---- 28/32 [openai]\n",
      "   ----------------------------------- ---- 28/32 [openai]\n",
      "   ----------------------------------- ---- 28/32 [openai]\n",
      "   ----------------------------------- ---- 28/32 [openai]\n",
      "   ----------------------------------- ---- 28/32 [openai]\n",
      "   ----------------------------------- ---- 28/32 [openai]\n",
      "   ----------------------------------- ---- 28/32 [openai]\n",
      "   ----------------------------------- ---- 28/32 [openai]\n",
      "   ----------------------------------- ---- 28/32 [openai]\n",
      "   ----------------------------------- ---- 28/32 [openai]\n",
      "   ----------------------------------- ---- 28/32 [openai]\n",
      "   ----------------------------------- ---- 28/32 [openai]\n",
      "   ----------------------------------- ---- 28/32 [openai]\n",
      "   ----------------------------------- ---- 28/32 [openai]\n",
      "   ----------------------------------- ---- 28/32 [openai]\n",
      "   ------------------------------------ --- 29/32 [langsmith]\n",
      "   ------------------------------------ --- 29/32 [langsmith]\n",
      "   ------------------------------------ --- 29/32 [langsmith]\n",
      "   ------------------------------------- -- 30/32 [langchain-core]\n",
      "   ------------------------------------- -- 30/32 [langchain-core]\n",
      "   ------------------------------------- -- 30/32 [langchain-core]\n",
      "   ------------------------------------- -- 30/32 [langchain-core]\n",
      "   ------------------------------------- -- 30/32 [langchain-core]\n",
      "   ------------------------------------- -- 30/32 [langchain-core]\n",
      "   -------------------------------------- - 31/32 [langchain-openai]\n",
      "   ---------------------------------------- 32/32 [langchain-openai]\n",
      "\n",
      "Successfully installed PyYAML-6.0.2 annotated-types-0.7.0 anyio-4.9.0 certifi-2025.4.26 charset-normalizer-3.4.2 distro-1.9.0 h11-0.16.0 httpcore-1.0.9 httpx-0.28.1 idna-3.10 jiter-0.10.0 jsonpatch-1.33 jsonpointer-3.0.0 langchain-core-0.3.61 langchain-openai-0.3.18 langsmith-0.3.42 openai-1.82.0 orjson-3.10.18 packaging-24.2 pydantic-2.11.5 pydantic-core-2.33.2 regex-2024.11.6 requests-2.32.3 requests-toolbelt-1.0.0 sniffio-1.3.1 tenacity-9.1.2 tiktoken-0.9.0 tqdm-4.67.1 typing-extensions-4.13.2 typing-inspection-0.4.1 urllib3-2.4.0 zstandard-0.23.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install openai langchain-openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0c5ff8e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAI\n",
    "\n",
    "llm = OpenAI()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "689658eb",
   "metadata": {},
   "source": [
    "## Chamando a LLM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe517d1d",
   "metadata": {},
   "source": [
    "### Chamada √∫nica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "07b7b795",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nAzul.'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"Qual o cor do c√©u?\"\n",
    "\n",
    "llm.invoke(question)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4f2c006",
   "metadata": {},
   "source": [
    "### Chamada via STREAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2ea871bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "O c√©u pode ter diferentes cores dependendo do hor√°rio do dia e das condi√ß√µes clim√°ticas. Durante o dia, o c√©u costuma ser azul, devido √† difus√£o da luz solar pelas mol√©culas de ar na atmosfera. No entanto, em dias nublados ou ao anoitecer, o c√©u pode ter tons de cinza, laranja, rosa ou vermelho. Durante a noite, o c√©u pode ser visto como preto, mas em √°reas com pouca polui√ß√£o luminosa, √© poss√≠vel ver estrelas e a Via L√°ctea, que d√£o um tom esverdeado ou azulado ao c√©u. "
     ]
    }
   ],
   "source": [
    "for text in llm.stream(question):\n",
    "    print(text, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6cdc843",
   "metadata": {},
   "source": [
    "### Chamadas m√∫ltiplas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3ece8a38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\n\\nO c√©u n√£o possui uma cor espec√≠fica, pode ser azul, rosa, laranja, roxo, entre outras, dependendo da hora do dia, das condi√ß√µes clim√°ticas e da localiza√ß√£o geogr√°fica.',\n",
       " '\\n\\nA cor do mar pode variar de acordo com a localiza√ß√£o, profundidade, clima e outros fatores. Geralmente, o mar pode apresentar tons de azul, verde, turquesa, cinza, marrom e at√© mesmo roxo em certas condi√ß√µes. ']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions = [\n",
    "    \"Qual o cor do c√©u?\",\n",
    "    \"Qual a cor do mar?\"\n",
    "    ]\n",
    "\n",
    "llm.batch(questions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26fd2929",
   "metadata": {},
   "source": [
    "# ChatModels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "901825d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "chat = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bfa94ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import SystemMessage, HumanMessage\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(content=\"Voc√™ √© um assistente muito bem humorado.\"),\n",
    "    HumanMessage(content=\"Por que o c√©u √© azul?\"),\n",
    "\n",
    "]\n",
    "\n",
    "output = chat.invoke(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31e55df2",
   "metadata": {},
   "source": [
    "### Imprimindo o resultado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4002dc19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O c√©u √© azul devido ao fen√¥meno conhecido como dispers√£o de Rayleigh, que ocorre quando a luz do sol atinge as mol√©culas na atmosfera terrestre. Essas mol√©culas espalham mais eficientemente a luz azul do que as outras cores do espectro vis√≠vel, o que faz com que enxerguemos o c√©u com esse tom caracter√≠stico. Ent√£o, podemos dizer que o c√©u √© azul porque as mol√©culas est√£o fazendo um \"favoritismo\" pela cor azul! üòâ\n"
     ]
    }
   ],
   "source": [
    "print(output.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9dd724b",
   "metadata": {},
   "source": [
    "### Metadata dos tokens usados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f11919c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'token_usage': {'completion_tokens': 126,\n",
       "  'prompt_tokens': 30,\n",
       "  'total_tokens': 156,\n",
       "  'completion_tokens_details': {'accepted_prediction_tokens': 0,\n",
       "   'audio_tokens': 0,\n",
       "   'reasoning_tokens': 0,\n",
       "   'rejected_prediction_tokens': 0},\n",
       "  'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}},\n",
       " 'model_name': 'gpt-3.5-turbo-0125',\n",
       " 'system_fingerprint': None,\n",
       " 'id': 'chatcmpl-BaRDrxA7A8QUOLaGWvOupGBtgjpar',\n",
       " 'service_tier': 'default',\n",
       " 'finish_reason': 'stop',\n",
       " 'logprobs': None}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.response_metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80750f2b",
   "metadata": {},
   "source": [
    "### Modo Stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ffc7f6dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O c√©u √© azul por causa do fen√¥meno conhecido como dispers√£o de Rayleigh, que ocorre quando a luz do sol atinge as mol√©culas de g√°s na atmosfera da Terra e √© espalhada em diferentes dire√ß√µes. A luz azul √© espalhada com mais facilidade do que outras cores do espectro de luz, o que resulta na apar√™ncia azul do c√©u. Ent√£o, o c√©u √© azul porque as mol√©culas de ar est√£o se divertindo jogando de forma desordenada a luz azul para todos os lados! Que brincadeira, n√©?"
     ]
    }
   ],
   "source": [
    "for text in chat.stream(messages):\n",
    "    print(text.content, end=\"\", flush=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
